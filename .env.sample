# Example environment configuration
# Base URL for Xinference server
XINFERENCE_URL=
# Whisper model used for transcription
XINFERENCE_MODEL=

# Ollama server base URL and model name
OLLAMA_BASE_URL=
OLLAMA_MODEL=
